{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithms with Israel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "import geopandas\n",
    "import shapely\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "!pip install info_gain\n",
    "from info_gain import info_gain\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm to search for the best feature set for C4.5 algorithm\n",
    "\n",
    "def forwardSearch(feats, x_train, y_train, x_test, y_test, number_features):\n",
    "    fset = []\n",
    "    potential_feats = feats.copy()\n",
    "    column_names = ['feature', 'auc']  \n",
    "    while(len(fset)<number_features):\n",
    "        feature_scores = pd.DataFrame(columns = column_names)\n",
    "        feature_scores['feature'] = potential_feats\n",
    "        feature_scores['auc'] = 0\n",
    "        feature_scores.set_index('feature', inplace=True)   \n",
    "        for f in potential_feats:\n",
    "            test_fset = fset.copy()\n",
    "            test_fset.append(f)\n",
    "            #print(\"test_fset: \", test_fset)\n",
    "            feature_scores.loc[f] = runC45(test_fset, x_train, y_train, x_test, y_test)         \n",
    "        #print('feature_scores: ', feature_scores)\n",
    "        my_max = feature_scores[feature_scores['auc']==feature_scores['auc'].max()].index\n",
    "        fset.append(my_max.tolist()[0])\n",
    "        potential_feats.remove(my_max.tolist()[0])\n",
    "        print(\"fset: \", fset, \"auc: \", feature_scores['auc'].max())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Israel earthquake data with all features defined train test and val\n",
    "data_dir = \"C:\\\\Users\\\\User\\\\Debbie\\\\Data\\\\\"\n",
    "file_path = data_dir + \"final_feature_data_used\\\\israel_train.csv\"\n",
    "fileToRead = open(file_path, mode='r')\n",
    "ca_train = pd.read_csv(fileToRead)\n",
    "fileToRead.close()\n",
    "file_path = data_dir + \"final_feature_data_used\\\\israel_val.csv\"\n",
    "fileToRead = open(file_path, mode='r')\n",
    "ca_val = pd.read_csv(fileToRead)\n",
    "fileToRead.close()\n",
    "file_path = data_dir + \"final_feature_data_used\\\\israel_test.csv\"\n",
    "fileToRead = open(file_path, mode='r')\n",
    "ca_test = pd.read_csv(fileToRead)\n",
    "fileToRead.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the variables\n",
    "x_train = ca_train.drop(['actual','mag_counts','region','year'], axis=1)\n",
    "y_train = ca_train['actual']\n",
    "x_test = ca_test.drop(['actual','mag_counts','region','year'], axis=1)\n",
    "y_test = ca_test['actual']\n",
    "x_val = ca_val.drop(['actual','mag_counts','region','year'], axis=1)\n",
    "y_val = ca_val['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val = x_train.append(x_val)\n",
    "y_train_val = y_train.append(y_val)\n",
    "y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using rapidminer I got the following results for Israel data IGR above 0.8 (27):\n",
    "igr_feats = ['rateE','x7','b','deltaM','x6_3','x6_7','ma4','ma7','x6_8'\n",
    "             ,'x6_9','x6_10','run25below_all','l1_mag_med','prob4','mse',\n",
    "             'prob1','x6_1' ,'x6_2','x6_4','x6_5','x6_6','count_above25_all',\n",
    "             'per_above_mean25_all','x1','x5','run25_below','l1_mag_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks_vars = ['b', 'ma1', 'prob1', 'ma2', 'prob2', 'ma3',\n",
    "       'prob3', 'ma4', 'prob4', 'ma5', 'prob5', 'ma6', 'prob6', 'ma7', 'prob7',\n",
    "       'ma8', 'prob8', 'ma9', 'prob9', 'ma10', 'prob10', 'tn', 'meanMag',\n",
    "       'rateE', 'mse', 'deltaM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = x_train.columns.to_list()\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.5 algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=10)\n",
    "# run c45 model and get auc to use in search \n",
    "def runC45(feat, x_train, y_train, x_test, y_test):   \n",
    "    c45 = model.fit(x_train[feat], y_train)\n",
    "    return roc_auc_score(y_test, c45.predict_proba(x_test[feat])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy',min_samples_split=10)\n",
    "\n",
    "# Routine to just to run c45 and get results\n",
    "def myC45(feat, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    c45 = model.fit(x_train[feat], y_train)\n",
    "    ca_predict = c45.predict(x_test[feat])\n",
    "    ca_predictions = c45.predict_proba(x_test[feat])\n",
    "    print('accuracy: ', accuracy_score(y_test, ca_predict), 'auc: ', roc_auc_score(y_test, ca_predictions[:,1]))\n",
    "    print(pd.DataFrame(\n",
    "        confusion_matrix(y_test, ca_predict),\n",
    "        columns=['Predicted Not Earthquake', 'Predicted Earthquake'],\n",
    "        index=['True Not Earthquake', 'True Earthquake'])\n",
    "    )\n",
    "    fpr, tpr, _ = roc_curve(y_test, ca_predictions[:,1])\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run C45 on all variables\n",
    "feats = x_train.columns.tolist()\n",
    "print('# of features:', len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search starting with all of the variables\n",
    "forwardSearch(feats, x_train, y_train, x_val, y_val, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['prob1', 'x7', 'prob5', 'prob9', 'run75all', 'run25below_all'] auc:  0.897\n",
    "['prob1', 'x7', 'run50all', 'run75below_all', 'run25all', 'prob10'] auc:  0.895\n",
    "['prob1', 'x7', 'prob5', 'prob9', 'run75all'] auc:  0.894\n",
    "['prob1', 'count_above50_all', 'x7', 'x6_2', 'run25', 'l9_mag_med'] auc:  0.873\n",
    "['prob1', 'x6_7', 'per_above_mean50_all', 'ma10', 'l9_mag_med', 'ma3'] auc:  0.872\n",
    "['prob1', 'x7', 'prob8', 'x6_9'] auc:  0.866\n",
    "['prob1', 'count_above50_all', 'x7', 'x6_2'] auc:  0.8616\n",
    "['prob1', 'x6_7', 'count_above50_all', 'run25_below', 'x6_6'] auc:  0.860\n",
    "['prob1', 'x6_7', 'per_above_mean50_all', 'x7', 'l9_mag_med', 'count_above50_all'] auc:  0.860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result from previously\n",
    "c45all_feats = ['prob1', 'x7', 'prob5','l7_mag_med','l5_mag_med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myC45(c45all_feats, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run c45 search on igr rapidminer features:\n",
    "forwardSearch(igr_feats, x_train, y_train, x_val, y_val, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
