{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new time series features for Israel earthquakes 22-4-20\n",
    "# this routine works on the main shocks only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "import geopandas\n",
    "import shapely\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to .1 so can round the magnitudes to get number earthquakes with a magnitude\n",
    "def mytenths(mag):\n",
    "    return round(.1 * math.floor(float(mag)/.1 + .00000001), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Israel earthquake data with shocks defined\n",
    "# caoo is all data and camain is main shocks\n",
    "# need to create new attributes on both\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\User\\\\Debbie\\\\Data\\\\\"\n",
    "file_path = data_dir + \"output\\\\israel_shocks.csv\"\n",
    "fileToRead = open(file_path, mode='r')\n",
    "caoo = pd.read_csv(fileToRead)\n",
    "fileToRead.close()\n",
    "caoo['datetime'] = pd.to_datetime(caoo['datetime'])\n",
    "caoo['year'] = caoo['datetime'].dt.year\n",
    "camain = caoo[caoo['shocks']=='S'][['region','year','mag','datetime']]\n",
    "camain.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = ['Eilat-Deep','Aragonese-Deep','Arava','E.Mediter.Sea','Cyprus','Dead-Sea-Basin','Lebanon',\n",
    "        'Sinai','Arnona-Dakar-Deep','Suez']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean mag and median mag for cluster and then # above and below for 12 largest clusters\n",
    "\n",
    "ca = camain[camain['region'].isin(regs)]\n",
    "# add mean for each cluster into the df\n",
    "ca0 = ca.join(ca.groupby('region')['mag'].mean(), on='region', rsuffix='_mean')\n",
    "ca1 = ca0.join(ca.groupby('region')['mag'].median(), on='region', rsuffix='_median')\n",
    "\n",
    "# indicate if the mag is above the mean\n",
    "ca1['above_mean'] = ca1.mag > ca1.mag_mean\n",
    "ca1['below_mean'] = ca1.mag < ca1.mag_mean\n",
    "#ca1['above_median'] = ca1.mag > ca1.mag_median\n",
    "#ca1['amt_above_median'] = ca1.mag - ca1.mag_median\n",
    "ca1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to calculate a run (above the mean, but here > 0 because it works on a column that is the mag - mean)\n",
    "# for a series which should be for one cluster sorted in order\n",
    "# this will be used in a lambda function to calculate the longest run for rolling windows\n",
    "\n",
    "def longestRun(df):\n",
    "    run = 0\n",
    "    longest_run = 0\n",
    "    for x in df:\n",
    "        if x :\n",
    "            run = run+1\n",
    "            if run > longest_run:\n",
    "                longest_run = run  \n",
    "        else:         \n",
    "            run = 0  \n",
    "    return longest_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the runs for sliding windows of 50 for all the earthquakes\n",
    "# run is number of earthquakes above the mean for the cluster\n",
    "pd.options.mode.chained_assignment = None \n",
    "runs = pd.DataFrame()\n",
    "for cl in regs:\n",
    "    ca2 = ca1[ca1.region==cl]\n",
    "    ca2['run25'] = ca2['above_mean'].shift(1).rolling(25).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run50'] = ca2['above_mean'].shift(1).rolling(50).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run75'] = ca2['above_mean'].shift(1).rolling(75).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run100'] = ca2['above_mean'].shift(1).rolling(100).apply(lambda x: longestRun(x), raw=True)\n",
    "    \n",
    "    ca2['run25_below'] = ca2['below_mean'].shift(1).rolling(25).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run50_below'] = ca2['below_mean'].shift(1).rolling(50).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run75_below'] = ca2['below_mean'].shift(1).rolling(75).apply(lambda x: longestRun(x), raw=True)\n",
    "    ca2['run100_below'] = ca2['below_mean'].shift(1).rolling(100).apply(lambda x: longestRun(x), raw=True)\n",
    "    \n",
    "    ca2['count_above50'] = ca2['above_mean'].shift(1).rolling(50).sum()\n",
    "    ca2['per_above_mean50'] = ca2.count_above50 / 50\n",
    "    ca2['count_above25'] = ca2['above_mean'].shift(1).rolling(25).sum()\n",
    "    ca2['per_above_mean25'] = ca2.count_above25 / 25\n",
    "    ca2['count_above75'] = ca2['above_mean'].shift(1).rolling(75).sum()\n",
    "    ca2['per_above_mean75'] = ca2.count_above75 / 75\n",
    "    ca2['count_above100'] = ca2['above_mean'].shift(1).rolling(100).sum()\n",
    "    ca2['per_above_mean100'] = ca2.count_above100 / 100\n",
    "    runs = pd.concat([runs,ca2])  # stack the new df on the old ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[['region','year','above_mean', 'below_mean', 'run25', 'run50', 'run75', 'run100',\n",
    "       'run25_below', 'run50_below']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_runs = pd.DataFrame()\n",
    "for cl in regs:\n",
    "    r1 = runs[runs['region']==cl].resample('Y', on='datetime').last()[['year','region',\n",
    "               'run25', 'run50', 'run75', 'run100', 'run25_below', 'run50_below', \n",
    "               'run75_below', 'run100_below','count_above50', 'per_above_mean50', 'count_above25',\n",
    "               'per_above_mean25', 'count_above75', 'per_above_mean75', 'count_above100', \n",
    "               'per_above_mean100']]\n",
    "    main_runs = pd.concat([main_runs,r1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_runs[25:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_dir + \"output\\\\israel_main_runs.csv\"\n",
    "main_runs.to_csv(file_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lag variables from meanMag and medianMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per cluster create mean and median mag and lag variables\n",
    "autos = pd.DataFrame()\n",
    "for cl in regs:\n",
    "    a0 = camain[camain['region']==cl][['mag','datetime','year','region']].reset_index(drop=True)\n",
    "    a1 = a0.join(a0.groupby('year')['mag'].mean(), on='year', rsuffix='_mean')\n",
    "    a2 = a1.join(a0.groupby('year')['mag'].median(), on='year', rsuffix='_median')  \n",
    "    a3 = a2.resample('Y', on='datetime').last()  \n",
    "    \n",
    "    a3[['mag_mean']] = a3[['mag_mean']].fillna(value=0)\n",
    "    a3[['mag_median']] = a3[['mag_median']].fillna(value=0)\n",
    "    autos = pd.concat([autos, a3])\n",
    "autos[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the lagged mean and median values - this is not by cluster so need to see how to deal with this\n",
    "# need to take for each cluster from 10 years out\n",
    "\n",
    "autos['l1_mag_mean'] = autos['mag_mean'].shift(1)\n",
    "autos['l2_mag_mean'] = autos['mag_mean'].shift(2)\n",
    "autos['l3_mag_mean'] = autos['mag_mean'].shift(3)\n",
    "autos['l4_mag_mean'] = autos['mag_mean'].shift(4)\n",
    "autos['l5_mag_mean'] = autos['mag_mean'].shift(5)\n",
    "autos['l6_mag_mean'] = autos['mag_mean'].shift(6)\n",
    "autos['l7_mag_mean'] = autos['mag_mean'].shift(7)\n",
    "autos['l8_mag_mean'] = autos['mag_mean'].shift(8)\n",
    "autos['l9_mag_mean'] = autos['mag_mean'].shift(9)\n",
    "autos['l10_mag_mean'] = autos['mag_mean'].shift(10)\n",
    "\n",
    "autos['l1_mag_med'] = autos['mag_median'].shift(1)\n",
    "autos['l2_mag_med'] = autos['mag_median'].shift(2)\n",
    "autos['l3_mag_med'] = autos['mag_median'].shift(3)\n",
    "autos['l4_mag_med'] = autos['mag_median'].shift(4)\n",
    "autos['l5_mag_med'] = autos['mag_median'].shift(5)\n",
    "autos['l6_mag_med'] = autos['mag_median'].shift(6)\n",
    "autos['l7_mag_med'] = autos['mag_median'].shift(7)\n",
    "autos['l8_mag_med'] = autos['mag_median'].shift(8)\n",
    "autos['l9_mag_med'] = autos['mag_median'].shift(9)\n",
    "autos['l10_mag_med'] = autos['mag_median'].shift(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_dir + \"output\\\\israel_auto_vars_new.csv\"\n",
    "autos.to_csv(file_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
